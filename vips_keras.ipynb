{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=256\n",
    "overl=0.5\n",
    "epochs=3\n",
    "modelname=\"model3_256\"\n",
    "batchsize=1\n",
    "training=True\n",
    "base='/home/jonassog/Projects/VipsML/ML2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build encoder done..\n",
      "Build decoder done..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import Sequence\n",
    "import pyvips as Vips\n",
    "from random import shuffle, choice\n",
    "from numpy import rot90, flip, frombuffer, uint8, asarray, squeeze\n",
    "from math import ceil, floor\n",
    "from functools import reduce\n",
    "\n",
    "#Non degrading data modulation\n",
    "def modulator(im, rotation, flippage):\n",
    "    if flippage:\n",
    "        return flip(rot90(im, k=rotation),axis=0)\n",
    "    else:\n",
    "        return rot90(im, k=rotation)\n",
    "\n",
    "class SegNetImage(Sequence):    \n",
    "    \"\"\"Generator class to be fed to a keras fit-function.\"\"\"\n",
    "\n",
    "    def __init__(self,imagePath,maskpath=None,frame=256,overlay=0.0, batchSize=10):\n",
    "        \"\"\"Args:\n",
    "            imagePath: Path to original image.\n",
    "            maskpath: Path to image masks, None if not training.\n",
    "            frame: Frame size (x and y dim)\n",
    "            overlay: How much overlay to keep between each piece of the image.\n",
    "            batchSize: Batchsize for feeding into CNN.\"\"\"\n",
    "        \n",
    "        self.orig=Vips.Image.new_from_file(imagePath)        \n",
    "        h,w,d = self.orig.width, self.orig.height, self.orig.bands        \n",
    "        self.origShape = (w,h,d)\n",
    "        self.frame=frame\n",
    "        self.overlay=round(self.frame*overlay)\n",
    "        self.step = self.frame-self.overlay        \n",
    "        self.batchSize=batchSize                \n",
    "        \n",
    "        #The last step will cover a whole frame\n",
    "        self.x_frames=ceil((w-(self.frame-self.step))/(self.step))\n",
    "        self.y_frames=ceil((h-(self.frame-self.step))/(self.step))        \n",
    "        self.total_frames=self.x_frames*self.y_frames\n",
    "        \n",
    "        # Fix padding \n",
    "        _w = ceil(self.x_frames*self.step)+(self.frame-self.step)\n",
    "        _h = ceil(self.y_frames*self.step)+(self.frame-self.step)\n",
    "        self.embeddedShape = (_w, _h, d)\n",
    "        self.orig=self.orig.embed(0,0,_w,_h,extend='white')    \n",
    "                \n",
    "        if maskpath == None:\n",
    "            self.training=False\n",
    "        else:\n",
    "            self.training=True\n",
    "            self.initMask(maskpath)\n",
    "            self.frame_order = list(range(self.total_frames))\n",
    "            # The fit function will randomize the batch order,\n",
    "            # but not the individual datasets inside each batch:\n",
    "            shuffle(self.frame_order)\n",
    "        \n",
    "    def initMask(self,maskpath):\n",
    "        self.mask=Vips.Image.new_from_file(maskpath)\n",
    "        self.mask=self.mask.embed(0,0,self.embeddedShape[0],self.embeddedShape[1],extend='black')\n",
    "        # We need a binary class matrix for training.\n",
    "        # We could use keras.utils.to_categorical downstream instead.\n",
    "        self.hist=self.mask.hist_find()\n",
    "        self.featureN = self.hist.width\n",
    "        features=list(range(self.featureN))\n",
    "        expanded = None\n",
    "        for f in features:\n",
    "            if expanded:\n",
    "                expanded=expanded.bandjoin(self.mask==f)\n",
    "            else:\n",
    "                expanded = self.mask==f\n",
    "        self.mask=expanded  \n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(ceil(self.total_frames/self.batchSize))\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # the keras.utils.Sequence expects one batch upon requesting an item\n",
    "        start = index*self.batchSize\n",
    "        end = min((index+1)*(self.batchSize),self.total_frames)\n",
    "        if self.training:\n",
    "            origs = []\n",
    "            masks = []\n",
    "            # We iterate one by one to assign random rotation and flipping\n",
    "            # to both image and mask\n",
    "            for i in self.frame_order[start:end]:\n",
    "                rot=choice(range(4))\n",
    "                flippage=choice(range(2))==1\n",
    "                origs += [self.getSingleItem(i,rot,flippage)]\n",
    "                # Output vector is expected to be 1D (could be fixed in the model definition):\n",
    "                masks += [self.getMask(i,rot,flippage).reshape((self.frame*self.frame,self.featureN))]\n",
    "            return asarray(origs),asarray(masks).astype(float)\n",
    "        else:\n",
    "            return asarray([self.getSingleItem(i) for i in range(start,end)])\n",
    "    \n",
    "    def getSingleItem(self,index,rot=0,flp=False):\n",
    "        rotations=[lambda x: x,lambda x: x.rot90(), lambda x: x.rot180(), lambda x: x.rot270()]\n",
    "        y = floor(index/self.x_frames)\n",
    "        x = index % self.x_frames\n",
    "        x_px = x*(self.step)\n",
    "        y_px = y*(self.step)\n",
    "        o=self.getImageAt(x_px, y_px, self.frame)\n",
    "        o=rotations[rot](o)\n",
    "        if flp:\n",
    "            o=o.fliphor()\n",
    "        return self.toNp(o)\n",
    "        \n",
    "    def getMask(self,index,rot=0,flp=False):\n",
    "        rotations=[lambda x: x,lambda x: x.rot90(), lambda x: x.rot180(), lambda x: x.rot270()]\n",
    "        y = floor(index/self.x_frames)\n",
    "        x = index % self.x_frames\n",
    "        x_px = x*(self.step)\n",
    "        y_px = y*(self.step)\n",
    "        o=self.getImageAt(x_px,y_px,self.frame,im=self.mask)\n",
    "        o=rotations[rot](o)\n",
    "        if flp:\n",
    "            o=o.fliphor()\n",
    "        return self.toNp(o)\n",
    "\n",
    "    def getShape(self):\n",
    "        return (self.frame, self.frame, 3)\n",
    "        \n",
    "    def toNp(self,im):\n",
    "        return frombuffer(im.write_to_memory(), dtype=uint8).reshape(im.height, im.width, im.bands)\n",
    "     \n",
    "    def getBoxFrom(self,x,y,w):\n",
    "        return (x,y,x+w,y+w)\n",
    "\n",
    "    def getImageAt(self,x,y,w,im=None):\n",
    "        if im is None:\n",
    "          im=self.orig\n",
    "        return im.crop(x,y,w,w)\n",
    "\n",
    "    def setBatchSize(self,n):\n",
    "        self.batchSize=n\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # re-randomize upon finishing an epoch\n",
    "        shuffle(self.frame_order)\n",
    "\n",
    "class MultiSegNetImage(Sequence):\n",
    "    def __init__(self,origs,masks=None,frame=256,overlay=0.0, batchSize=10):\n",
    "        self.frame=frame\n",
    "        self.overlay=overlay\n",
    "        self.batchSize=batchSize\n",
    "        self.training = masks!=None\n",
    "        self.images = [SegNetImage(origs[i],masks[i] if self.training else None,frame,overlay,batchSize) for i in range(len(origs))]\n",
    "        self.indices = reduce(lambda acc, val: acc+[(val,i) for i in range(self.images[val].total_frames)],range(len(self.images)),[])\n",
    "        shuffle(self.indices)\n",
    "    \n",
    "    def getShape(self):\n",
    "        \"\"\" Peek ahead at first image in stack\"\"\"\n",
    "        return self.images[0].getShape()\n",
    "    \n",
    "    def totalItems(self):\n",
    "        \"\"\" Total number of items \"\"\"\n",
    "        return len(self.indices)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\" Number of batches, not items \"\"\"\n",
    "        return int(ceil(self.totalItems()/self.batchSize))\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \"\"\" One batch, not one item \"\"\"\n",
    "        start = index*self.batchSize\n",
    "        end = min((index+1)*(self.batchSize),self.totalItems())\n",
    "        if self.training:\n",
    "            origs = []\n",
    "            masks = []\n",
    "            # We iterate one by one to assign (same) random rotation\n",
    "            # and flipping to both image and mask\n",
    "            for entry in self.indices[start:end]:\n",
    "                imageN,itemN = entry\n",
    "                image=self.images[imageN]\n",
    "                rot=choice(range(4))\n",
    "                flippage=choice(range(2))==1\n",
    "                origs += [image.getSingleItem(itemN,rot,flippage)]\n",
    "                # Output vector is expected to be 1D (could be fixed in the model definition):\n",
    "                masks += [image.getMask(itemN,rot,flippage).reshape((image.frame*image.frame,image.featureN))]\n",
    "            return asarray(origs),asarray(masks).astype(float)\n",
    "        else:\n",
    "            return asarray([self.images[i].getSingleItem(n) for i,n in indices[start:end]])\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # re-randomize upon finishing an epoch\n",
    "        shuffle(self.indices)\n",
    "            \n",
    "          \n",
    "s=MultiSegNetImage([base+'/00-orig.tif',base+'/00-orig.tif'],masks=[base+'/test2.tiff',base+'/test2.tiff'],frame=size,overlay=overl,batchSize=batchsize)\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "K.set_floatx('float32')\n",
    "K.set_epsilon(1e-7) \n",
    "\n",
    "class MaxPoolingWithArgmax2D(Layer):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            pool_size=(2, 2),\n",
    "            strides=(2, 2),\n",
    "            padding='same',\n",
    "            **kwargs):\n",
    "        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n",
    "        self.padding = padding\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        padding = self.padding\n",
    "        pool_size = self.pool_size\n",
    "        strides = self.strides\n",
    "        if K.backend() == 'tensorflow':\n",
    "            ksize = [1, pool_size[0], pool_size[1], 1]\n",
    "            padding = padding.upper()\n",
    "            strides = [1, strides[0], strides[1], 1]\n",
    "            output, argmax = K.tf.nn.max_pool_with_argmax(\n",
    "                    inputs,\n",
    "                    ksize=ksize,\n",
    "                    strides=strides,\n",
    "                    padding=padding)\n",
    "        else:\n",
    "            errmsg = '{} backend is not supported for layer {}'.format(\n",
    "                    K.backend(), type(self).__name__)\n",
    "            raise NotImplementedError(errmsg)\n",
    "        argmax = K.cast(argmax, K.floatx())\n",
    "        return [output, argmax]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        ratio = (1, 2, 2, 1)\n",
    "        output_shape = [\n",
    "                dim//ratio[idx]\n",
    "                if dim is not None else None\n",
    "                for idx, dim in enumerate(input_shape)]\n",
    "        output_shape = tuple(output_shape)\n",
    "        return [output_shape, output_shape]\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return 2 * [None]\n",
    "\n",
    "\n",
    "class MaxUnpooling2D(Layer):\n",
    "    def __init__(self, size=(2, 2), **kwargs):\n",
    "        super(MaxUnpooling2D, self).__init__(**kwargs)\n",
    "        self.size = size\n",
    "\n",
    "    def call(self, inputs, output_shape=None):\n",
    "        updates, mask = inputs[0], inputs[1]\n",
    "        with K.tf.variable_scope(self.name):\n",
    "            mask = K.cast(mask, 'int32')\n",
    "            input_shape = K.tf.shape(updates, out_type='int32')\n",
    "            #  calculation new shape\n",
    "            if output_shape is None:\n",
    "                output_shape = (\n",
    "                        input_shape[0],\n",
    "                        input_shape[1]*self.size[0],\n",
    "                        input_shape[2]*self.size[1],\n",
    "                        input_shape[3])\n",
    "            self.output_shape1 = output_shape\n",
    "\n",
    "            # calculation indices for batch, height, width and feature maps\n",
    "            one_like_mask = K.ones_like(mask, dtype='int32')\n",
    "            batch_shape = K.concatenate(\n",
    "                    [[input_shape[0]], [1], [1], [1]],\n",
    "                    axis=0)\n",
    "            batch_range = K.reshape(\n",
    "                    K.tf.range(output_shape[0], dtype='int32'),\n",
    "                    shape=batch_shape)\n",
    "            b = one_like_mask * batch_range\n",
    "            y = mask // (output_shape[2] * output_shape[3])\n",
    "            x = (mask // output_shape[3]) % output_shape[2]\n",
    "            feature_range = K.tf.range(output_shape[3], dtype='int32')\n",
    "            f = one_like_mask * feature_range\n",
    "\n",
    "            # transpose indices & reshape update values to one dimension\n",
    "            updates_size = K.tf.size(updates)\n",
    "            indices = K.transpose(K.reshape(\n",
    "                K.stack([b, y, x, f]),\n",
    "                [4, updates_size]))\n",
    "            values = K.reshape(updates, [updates_size])\n",
    "            ret = K.tf.scatter_nd(indices, values, output_shape)\n",
    "            return ret\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        mask_shape = input_shape[1]\n",
    "        return (\n",
    "                mask_shape[0],\n",
    "                mask_shape[1]*self.size[0],\n",
    "                mask_shape[2]*self.size[1],\n",
    "                mask_shape[3]\n",
    "                )\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Reshape\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "#from layers import MaxPoolingWithArgmax2D, MaxUnpooling2D\n",
    "\n",
    "\n",
    "def segnet(\n",
    "        input_shape,\n",
    "        n_labels,\n",
    "        kernel=3,\n",
    "        pool_size=(2, 2),\n",
    "        output_mode=\"softmax\"):\n",
    "    # encoder\n",
    "    inputs = Input(batch_shape=(None,)+input_shape)\n",
    "\n",
    "    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n",
    "    conv_1 = BatchNormalization()(conv_1)\n",
    "    conv_1 = Activation(\"relu\")(conv_1)\n",
    "    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n",
    "    conv_2 = BatchNormalization()(conv_2)\n",
    "    conv_2 = Activation(\"relu\")(conv_2)\n",
    "\n",
    "    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n",
    "\n",
    "    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n",
    "    conv_3 = BatchNormalization()(conv_3)\n",
    "    conv_3 = Activation(\"relu\")(conv_3)\n",
    "    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n",
    "    conv_4 = BatchNormalization()(conv_4)\n",
    "    conv_4 = Activation(\"relu\")(conv_4)\n",
    "\n",
    "    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n",
    "\n",
    "    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n",
    "    conv_5 = BatchNormalization()(conv_5)\n",
    "    conv_5 = Activation(\"relu\")(conv_5)\n",
    "    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n",
    "    conv_6 = BatchNormalization()(conv_6)\n",
    "    conv_6 = Activation(\"relu\")(conv_6)\n",
    "    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n",
    "    conv_7 = BatchNormalization()(conv_7)\n",
    "    conv_7 = Activation(\"relu\")(conv_7)\n",
    "\n",
    "    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n",
    "\n",
    "    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n",
    "    conv_8 = BatchNormalization()(conv_8)\n",
    "    conv_8 = Activation(\"relu\")(conv_8)\n",
    "    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n",
    "    conv_9 = BatchNormalization()(conv_9)\n",
    "    conv_9 = Activation(\"relu\")(conv_9)\n",
    "    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n",
    "    conv_10 = BatchNormalization()(conv_10)\n",
    "    conv_10 = Activation(\"relu\")(conv_10)\n",
    "\n",
    "    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n",
    "\n",
    "    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n",
    "    conv_11 = BatchNormalization()(conv_11)\n",
    "    conv_11 = Activation(\"relu\")(conv_11)\n",
    "    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n",
    "    conv_12 = BatchNormalization()(conv_12)\n",
    "    conv_12 = Activation(\"relu\")(conv_12)\n",
    "    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n",
    "    conv_13 = BatchNormalization()(conv_13)\n",
    "    conv_13 = Activation(\"relu\")(conv_13)\n",
    "\n",
    "    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n",
    "    print(\"Build encoder done..\")\n",
    "\n",
    "    # decoder\n",
    "\n",
    "    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n",
    "\n",
    "    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_1)\n",
    "    conv_14 = BatchNormalization()(conv_14)\n",
    "    conv_14 = Activation(\"relu\")(conv_14)\n",
    "    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n",
    "    conv_15 = BatchNormalization()(conv_15)\n",
    "    conv_15 = Activation(\"relu\")(conv_15)\n",
    "    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n",
    "    conv_16 = BatchNormalization()(conv_16)\n",
    "    conv_16 = Activation(\"relu\")(conv_16)\n",
    "\n",
    "    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])\n",
    "\n",
    "    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_2)\n",
    "    conv_17 = BatchNormalization()(conv_17)\n",
    "    conv_17 = Activation(\"relu\")(conv_17)\n",
    "    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n",
    "    conv_18 = BatchNormalization()(conv_18)\n",
    "    conv_18 = Activation(\"relu\")(conv_18)\n",
    "    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_18)\n",
    "    conv_19 = BatchNormalization()(conv_19)\n",
    "    conv_19 = Activation(\"relu\")(conv_19)\n",
    "\n",
    "    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n",
    "\n",
    "    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\")(unpool_3)\n",
    "    conv_20 = BatchNormalization()(conv_20)\n",
    "    conv_20 = Activation(\"relu\")(conv_20)\n",
    "    conv_21 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_20)\n",
    "    conv_21 = BatchNormalization()(conv_21)\n",
    "    conv_21 = Activation(\"relu\")(conv_21)\n",
    "    conv_22 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_21)\n",
    "    conv_22 = BatchNormalization()(conv_22)\n",
    "    conv_22 = Activation(\"relu\")(conv_22)\n",
    "\n",
    "    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])\n",
    "\n",
    "    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\")(unpool_4)\n",
    "    conv_23 = BatchNormalization()(conv_23)\n",
    "    conv_23 = Activation(\"relu\")(conv_23)\n",
    "    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_23)\n",
    "    conv_24 = BatchNormalization()(conv_24)\n",
    "    conv_24 = Activation(\"relu\")(conv_24)\n",
    "\n",
    "    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n",
    "\n",
    "    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\")(unpool_5)\n",
    "    conv_25 = BatchNormalization()(conv_25)\n",
    "    conv_25 = Activation(\"relu\",name='25')(conv_25)\n",
    "\n",
    "    conv_26 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_25)\n",
    "    conv_26 = BatchNormalization()(conv_26)\n",
    "    conv_26 = Reshape(\n",
    "            (input_shape[0] * input_shape[1], n_labels),\n",
    "            input_shape=(input_shape[0], input_shape[1], n_labels))(conv_26)\n",
    "\n",
    "    outputs = Activation(output_mode,name='out')(conv_26)\n",
    "    print(\"Build decoder done..\")\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"SegNet\")\n",
    "\n",
    "    return model\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "INIT_LR = (10**(-3))*1.5\n",
    "EPOCHS = epochs\n",
    "BS = 64\n",
    "\n",
    "model=segnet(\n",
    "        s.getShape(),\n",
    "        5,\n",
    "        kernel=3,\n",
    "        pool_size=(2, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 164/4018 [>.............................] - ETA: 40:47 - loss: 241.8981 - categorical_accuracy: 0.6819"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4c2ed1d08955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         metrics=[\"categorical_accuracy\"])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodelname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if training:\n",
    "    opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    H = model.fit_generator(s,epochs=EPOCHS)\n",
    "    model.save(base+\"/\" + modelname)\n",
    "\n",
    "if not training:\n",
    "    model.load_weights(base+\"/\" +modelname)\n",
    "    from matplotlib import pyplot as plt\n",
    "    import numpy as np\n",
    "    from random import shuffle\n",
    "\n",
    "    plt.figure(figsize = (50,20))\n",
    "    rs=list(range(len(s)))\n",
    "    shuffle(rs)\n",
    "    si=20\n",
    "    f, axarr = plt.subplots(si,3,figsize=(20,100))\n",
    "\n",
    "    for i in range(si):\n",
    "      dta2=model.predict(asarray([s.getSingleItem(rs[i])]))\n",
    "      dta2=squeeze(dta2,axis=0)\n",
    "      dta2=dta2.reshape((size,size,5))\n",
    "\n",
    "      axarr[i][0].imshow(np.argmax(dta2,axis=2),vmax=4,cmap='hot')\n",
    "\n",
    "      axarr[i][1].imshow(s.getSingleItem(rs[i]))\n",
    "      axarr[i][2].imshow(np.argmax(s.getMask(rs[i]),axis=2),vmax=4,cmap='hot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
